from PyQt5.QtWidgets import *
from PyQt5.QtGui import *
from PyQt5.QtCore import *
from PyQt5.QtWidgets import * #여러 QT라이브러리들 가져옴

import cv2     #opencv 라이브러리
import threading  #thread를 위한 라이브러리
import RPi.GPIO as GPIO #라즈베리파이 라이브러리
from scipy.spatial import distance as dist #거리계산할때 쓰이는 라이브러리
from imutils import face_utils # facial landmark 탐지시 필요한 라이브러리

import numpy as np

import dlib #이미지처리 및 안드로이드에 필요한 라이브러리

import sys,os

GPIO.setmode(GPIO.BCM) #BCM 모드로 사용하겠다.
GPIO.setup(26, GPIO.OUT)#pinMode(26,OUTPUT) 부저

def eye_aspect_ratio(eye):

        A = dist.euclidean(eye[1], eye[5])
        B = dist.euclidean(eye[2], eye[4])
        C = dist.euclidean(eye[0], eye[3])
        
        ear = (A + B) / (2.0 * C)

        return ear

print("[INFO] loading facial landmark predictor...")
detector = dlib.get_frontal_face_detector() #얼굴의 앞면을 인식하는 클래스생성
predictor = dlib.shape_predictor("/home/pi/shape_predictor_68_face_landmarks.dat") #인식된 얼굴에서 랜드마크 찿기위한 클래스 형성
                                                                                    #학습된 랜드마크 모델데이터 경로

 
(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"] # 왼쪽눈검출 랜드마크 
(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"] #오른쪽 눈 검출 랜드마크

vs = cv2.VideoCapture(-1) # 캡쳐 객체 형성

 
global makegroup
makegroup = 0

def cam():

    global makegroup
    global PERSON_GROUP_ID
    global img , recogTime
    global train
    global number

    openflag = 0
    EYE_AR_THRESH = 0.23
    EYE_AR_CONSEC_FRAMES = 7
    faceCOUNTER = 0
    COUNTER = 0
    TOTAL = 0

    while True:

        ret , frame = vs.read() #frame 하나씩 읽어 들인다.
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 흑백톤으로 변경 =>데이터 전처리작업

        rects = detector(gray, 0)#얼굴을 검출

        if len(rects) == 0: #얼굴검출이안되면p
            faceCOUNTER += 1 #카운트를 1올려줌
        if faceCOUNTER >= 7: #얼굴검출이 7번연속안될떄
            print ('no Face')

            #if time.time() - spTime > 10:

        for rect in rects: #검출이 되면

            faceCOUNTER = 0 # 얼굴이 검출안되는 카운트는 초기화
            shape = predictor(gray, rect) # 흑백톤으로 변경된 얼굴검출된 frame을 넣어주어 추론점 반환
            shape = face_utils.shape_to_np(shape) #모든 얼굴의 랜드마크 추출 후 좌표 변환

            leftEye = shape[lStart:lEnd] #왼쪽눈의 시작부터 끝점까지의 좌표를 leftEye에 넣음
            rightEye = shape[rStart:rEnd] #오른쪽 눈의 시작부터 끝점 까지의 좌표를 rightEye에 넣음
            leftEAR = eye_aspect_ratio(leftEye) #eye_aspect_ratio 함수를 통해 leftEar의 좌표를 구함
            rightEAR = eye_aspect_ratio(rightEye)#eye_aspect_ratio 함수를 통해 rightEar의 좌표를 구함

            ear = (leftEAR + rightEAR) / 2.0 # 최종Ear 결정

            leftEyeHull = cv2.convexHull(leftEye) # 왼쪽 눈의 테두리에 대한 정보를 얻음
            rightEyeHull = cv2.convexHull(rightEye)# 오른쪽 눈의 테두리에 대한 정보를 얻음

            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1) #화면상에보이는 눈 테두리 그림
            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1) # image, contour정보, contours list type에서 
#몇번째 contours line을 그릴 것인지. -1 이면 전체,칼라, 두께

            if ear < EYE_AR_THRESH: # Threshold=0.23 보다 작으면

                print ("blink" , end = '')
                COUNTER += 1 # 눈을 깜박였다고 출력하고 카운트 올림

            else:

                print ('open Eye', end = '') 
                COUNTER -= 1 #눈을 뜨고있다고 출력하고 카운트 내림

            if COUNTER < 0: 
                COUNTER = 0 #카운트 초기화

            elif COUNTER >= EYE_AR_CONSEC_FRAMES: #conuter가 7과 같거나 크면
                COUNTER = EYE_AR_CONSEC_FRAMES    # counter은 7로 맞춤

                print ('close Eye', end = '')   #r그리고 눈을 감고있다는것을 출력함

            elif COUNTER == 0: #정상으로 돌아옴
                GPIO.output(26,False) #led 부저 전부 종료

            elif COUNTER  > 3: #3번이상 눈을 감았다고 판단되면 
                GPIO.output(26,True) #부저를 울리게한다.

            print ("\teye : " + str(int(ear * 100)) + "\t" + str(COUNTER))

        cv2.imwrite('/home/pi/pic.jpg', frame)
        img.setPixmap(QPixmap('/home/pi/pic.jpg')) #카메라화면 표시

    video_capture.release() #캡쳐 객체해제
    cv2.destroyAllWindows() 

 

class hardCtl(QWidget): #메인화면 생성 클래스

    def __init__(self, parent=None):

        super(hardCtl, self).__init__(parent)

        img = QLabel(self) # 카메라 화면

        img.move(100,0)
        img.resize(640, 480)
        img.setPixmap(QPixmap('/home/pi/pic.jpg')) # 카메라화면 세부사항 설정

        t2 = threading.Thread(target = cam) #cam함수를 target으로 받아 Thread실행
        t2.daemon = True #thread를 데몬모드로 하여서 메인프로그램의 종료를 막지않고 실행
        t2.start() #실행시작
        
        self.showFullScreen() #풀스크린으로 화면 출력

 

app = QApplication(sys.argv) #QT실행
sb = hardCtl()
sb.resize(800, 480)
sb.move(0, 0)
